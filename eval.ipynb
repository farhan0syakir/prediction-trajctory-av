{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015873,
     "end_time": "2020-11-14T18:44:28.531099",
     "exception": false,
     "start_time": "2020-11-14T18:44:28.515226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook is based on [Lyft: Complete train and prediction pipeline](https://www.kaggle.com/huanvo/lyft-complete-train-and-prediction-pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 3.759767,
     "end_time": "2020-11-14T18:44:32.306658",
     "exception": false,
     "start_time": "2020-11-14T18:44:28.546891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../lib/lyft-l5kit-unofficial-fix')\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "from tempfile import gettempdir\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.resnet import resnet50, resnet18, resnet34, resnet101\n",
    "from tqdm import tqdm\n",
    "\n",
    "import l5kit\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.024604,
     "end_time": "2020-11-14T18:44:32.346456",
     "exception": false,
     "start_time": "2020-11-14T18:44:32.321852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l5kit.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.027521,
     "end_time": "2020-11-14T18:44:32.389560",
     "exception": false,
     "start_time": "2020-11-14T18:44:32.362039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016003,
     "end_time": "2020-11-14T18:44:32.421717",
     "exception": false,
     "start_time": "2020-11-14T18:44:32.405714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.031382,
     "end_time": "2020-11-14T18:44:32.469427",
     "exception": false,
     "start_time": "2020-11-14T18:44:32.438045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Lyft configs ---\n",
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'data_path': \"../input/lyft-motion-prediction-autonomous-vehicles\",\n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnet34',\n",
    "        'history_num_frames': 10,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1,\n",
    "        'model_name': \"model_resnet34_output\",\n",
    "        'lr': 1e-3,\n",
    "#         'weight_path': \"../input/lyft-pretrained-model-hv/model_multi_update_lyft_public.pth\",\n",
    "        'weight_path': \"./models/model_lstm0_output_70000_plus_40000.pth\",\n",
    "        'train': False,\n",
    "        'predict': True\n",
    "    },\n",
    "\n",
    "    'raster_params': {\n",
    "        'raster_size': [224, 224],\n",
    "        'pixel_size': [0.5, 0.5],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5\n",
    "    },\n",
    "\n",
    "    'train_data_loader': {\n",
    "        'key': 'scenes/train.zarr',\n",
    "        'batch_size': 16,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "    \n",
    "    'test_data_loader': {\n",
    "        'key': 'scenes/test.zarr',\n",
    "        'batch_size': 32,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "\n",
    "    'train_params': {\n",
    "        'max_num_steps': 101,\n",
    "        'checkpoint_every_n_steps': 20,\n",
    "    },\n",
    "       'val_data_loader': {\n",
    "        'key': 'scenes/validate_chopped_100/validate.zarr',\n",
    "        'batch_size': 16,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 8\n",
    "    },\n",
    "    'val_params': {\n",
    "        'max_num_steps': 5000,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.029183,
     "end_time": "2020-11-14T18:44:32.515746",
     "exception": false,
     "start_time": "2020-11-14T18:44:32.486563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set env variable for data\n",
    "DIR_INPUT = cfg[\"data_path\"]\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
    "dm = LocalDataManager(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015892,
     "end_time": "2020-11-14T18:44:32.547543",
     "exception": false,
     "start_time": "2020-11-14T18:44:32.531651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.038669,
     "end_time": "2020-11-14T18:44:32.602967",
     "exception": false,
     "start_time": "2020-11-14T18:44:32.564298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Function utils ---\n",
    "# Original code from https://github.com/lyft/l5kit/blob/20ab033c01610d711c3d36e1963ecec86e8b85b6/l5kit/l5kit/evaluation/metrics.py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_batch(\n",
    "    gt: Tensor, pred: Tensor, confidences: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Compute a negative log-likelihood for the multi-modal scenario.\n",
    "    log-sum-exp trick is used here to avoid underflow and overflow, For more information about it see:\n",
    "    https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations\n",
    "    https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/\n",
    "    https://leimao.github.io/blog/LogSumExp/\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(modes)x(time)x(2D coords)\n",
    "        confidences (Tensor): array of shape (bs)x(modes) with a confidence for each mode in each sample\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
    "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
    "\n",
    "    assert gt.shape == (batch_size, future_len, num_coords), f\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\n",
    "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
    "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
    "    assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
    "    # assert all data are valid\n",
    "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
    "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
    "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
    "    assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
    "\n",
    "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
    "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
    "    avails = avails[:, None, :, None]  # add modes and cords\n",
    "\n",
    "    # error (batch_size, num_modes, future_len)\n",
    "    error = torch.sum(((gt - pred) * avails) ** 2, dim=-1)  # reduce coords and use availability\n",
    "\n",
    "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
    "        # error (batch_size, num_modes)\n",
    "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
    "\n",
    "    # use max aggregator on modes for numerical stability\n",
    "    # error (batch_size, num_modes)\n",
    "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
    "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
    "    # print(\"error\", error)\n",
    "    return torch.mean(error)\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_single(\n",
    "    gt: Tensor, pred: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    # pred (bs)x(time)x(2D coords) --> (bs)x(mode=1)x(time)x(2D coords)\n",
    "    # create confidence (bs)x(mode=1)\n",
    "    batch_size, future_len, num_coords = pred.shape\n",
    "    confidences = pred.new_ones((batch_size, 1))\n",
    "    return pytorch_neg_multi_log_likelihood_batch(gt, pred.unsqueeze(1), confidences, avails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01608,
     "end_time": "2020-11-14T18:44:32.635005",
     "exception": false,
     "start_time": "2020-11-14T18:44:32.618925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018033,
     "end_time": "2020-11-14T18:44:32.669615",
     "exception": false,
     "start_time": "2020-11-14T18:44:32.651582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next we define the baseline model. Note that this model will return three possible trajectories together with confidence score for each trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.038741,
     "end_time": "2020-11-14T18:44:32.725753",
     "exception": false,
     "start_time": "2020-11-14T18:44:32.687012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/solved-concatenate-time-distributed-cnn-with-lstm/15435\n",
    "class LyftMultiModel(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg: Dict, num_modes=3):\n",
    "        super().__init__()\n",
    "\n",
    "        architecture = cfg[\"model_params\"][\"model_architecture\"]\n",
    "        backbone = eval(architecture)(pretrained=True, progress=True)\n",
    "        self.backbone = backbone\n",
    "\n",
    "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
    "        num_in_channels = 3 + num_history_channels\n",
    "\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.backbone.conv1.out_channels,\n",
    "            kernel_size=self.backbone.conv1.kernel_size,\n",
    "            stride=self.backbone.conv1.stride,\n",
    "            padding=self.backbone.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        # This is 512 for resnet18 and resnet34;\n",
    "        # And it is 2048 for the other resnets\n",
    "        \n",
    "        if architecture == \"resnet50\":\n",
    "            backbone_out_features = 2048\n",
    "        else:\n",
    "            backbone_out_features = 512\n",
    "\n",
    "        # X, Y coords for the future positions (output shape: batch_sizex50x2)\n",
    "        self.future_len = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        num_targets = 2 * self.future_len\n",
    "\n",
    "        # You can add more layers here.\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.LSTM(64, 512, 2, batch_first=True)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.num_preds = num_targets * num_modes\n",
    "        self.num_modes = num_modes\n",
    "\n",
    "        self.logit = nn.Linear(4096, out_features=self.num_preds + num_modes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, timesteps, H, W = x.size()\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        x = self.backbone.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = x.view(batch_size, 8, 64)\n",
    "        x, state = self.head(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.logit(x)\n",
    "\n",
    "        # pred (batch_size)x(modes)x(time)x(2D coords)\n",
    "        # confidences (batch_size)x(modes)\n",
    "        bs, _ = x.shape\n",
    "        pred, confidences = torch.split(x, self.num_preds, dim=1)\n",
    "        pred = pred.view(bs, self.num_modes, self.future_len, 2)\n",
    "        assert confidences.shape == (bs, self.num_modes)\n",
    "        confidences = torch.softmax(confidences, dim=1)\n",
    "        return pred, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.026048,
     "end_time": "2020-11-14T18:44:32.768356",
     "exception": false,
     "start_time": "2020-11-14T18:44:32.742308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward(data, model, device, criterion = pytorch_neg_multi_log_likelihood_batch):\n",
    "    inputs = data[\"image\"].to(device)\n",
    "    target_availabilities = data[\"target_availabilities\"].to(device)\n",
    "    targets = data[\"target_positions\"].to(device)\n",
    "    # Forward pass\n",
    "    preds, confidences = model(inputs)\n",
    "    loss = criterion(targets, preds, confidences, target_availabilities)\n",
    "    return loss, preds, confidences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016488,
     "end_time": "2020-11-14T18:44:32.801497",
     "exception": false,
     "start_time": "2020-11-14T18:44:32.785009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let us initialize the model and load the pretrained weights. Note that since the pretrained model was trained on GPU, you also need to enable GPU when running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 9.323214,
     "end_time": "2020-11-14T18:44:42.141249",
     "exception": false,
     "start_time": "2020-11-14T18:44:32.818035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 3.175144,
     "end_time": "2020-11-14T18:44:45.335448",
     "exception": false,
     "start_time": "2020-11-14T18:44:42.160304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/lyft/l5kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.041162,
     "end_time": "2020-11-14T18:44:45.408271",
     "exception": false,
     "start_time": "2020-11-14T18:44:45.367109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "import sys\n",
    "sys.path.append('../l5kit/l5kit/l5kit/evaluation')\n",
    "\n",
    "from csv_utils import read_gt_csv, read_pred_csv, write_gt_csv, write_pred_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 8.058477,
     "end_time": "2020-11-14T18:44:53.493960",
     "exception": false,
     "start_time": "2020-11-14T18:44:45.435483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid 5000\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "random_seed = 42 + 5\n",
    "shuffle_dataset = True\n",
    "\n",
    "# ===== INIT VAL DATASET============================================================\n",
    "eval_base_path = '../input/lyft-validate-chopped'\n",
    "eval_cfg = cfg[\"val_data_loader\"]\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "eval_zarr_path = str(Path(eval_base_path) / 'validate.zarr' )\n",
    "eval_mask_path = str(Path(eval_base_path) / \"mask.npz\")\n",
    "eval_gt_path = str(Path(eval_base_path) / \"gt.csv\")\n",
    "\n",
    "eval_zarr = ChunkedDataset(eval_zarr_path).open()\n",
    "eval_mask = np.load(eval_mask_path)[\"arr_0\"]\n",
    "# ===== INIT DATASET AND LOAD MASK\n",
    "eval_dataset = AgentDataset(cfg, eval_zarr, rasterizer, agents_mask=eval_mask)\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(eval_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = cfg[\"val_params\"][\"max_num_steps\"]\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "val_indices = indices[:split]\n",
    "\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "val_dataloader = DataLoader(eval_dataset, sampler=valid_sampler, batch_size=eval_cfg[\"batch_size\"], \n",
    "                             num_workers=eval_cfg[\"num_workers\"])\n",
    "\n",
    "print(\"Valid {}\".format(len(val_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 18.901857,
     "end_time": "2020-11-14T18:45:12.422679",
     "exception": false,
     "start_time": "2020-11-14T18:44:53.520822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth_path = eval_gt_path\n",
    "ground_truth = OrderedDict()\n",
    "inference = OrderedDict()\n",
    "\n",
    "for el in read_gt_csv(ground_truth_path):\n",
    "    ground_truth[el[\"track_id\"] + el[\"timestamp\"]] = el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ==== INIT MODEL=================\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LyftMultiModel(cfg)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 435.58303,
     "end_time": "2020-11-14T18:52:28.033472",
     "exception": false,
     "start_time": "2020-11-14T18:45:12.450442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [02:49<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_lstm0_output_416k_plus_0.pth 23.333442194270038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [02:00<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_lstm0_output_416k_plus_1000.pth 23.781278421274926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:49<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_lstm0_output_416k_plus_2000.pth 21.758474613787822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:49<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_lstm0_output_416k_plus_3000.pth 24.35036150883883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:52<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_lstm0_output_416k_plus_4000.pth 24.477072077351455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:53<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_lstm0_output_416k_plus_5000.pth 24.376116937804383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:51<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_lstm0_output_416k_plus_6000.pth 25.06165768913196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:52<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_lstm0_output_416k_plus_7000.pth 25.008784969581914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:53<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_lstm0_output_416k_plus_8000.pth 26.910025346427247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:51<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_lstm0_output_416k_plus_9000.pth 24.11895601499331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:53<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_lstm0_output_416k_plus_10000.pth 27.089822207158363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:50<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_lstm0_output_416k_plus_11000.pth 23.393010103532834\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(0,12000, 1000):\n",
    "    weight_path = \"./models/model_lstm0_output_416k_plus_\"+str(i)+\".pth\"\n",
    "    #load weight if there is a pretrained model\n",
    "    if weight_path:\n",
    "        model.load_state_dict(torch.load(weight_path))\n",
    "\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=cfg[\"model_params\"][\"lr\"])\n",
    "    print(f'device {device}')\n",
    "\n",
    "    # ==== EVAL LOOP\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    # store information for evaluation\n",
    "    future_coords_offsets_pd = []\n",
    "    timestamps = []\n",
    "    confidences_list = []\n",
    "    agent_ids = []\n",
    "\n",
    "    progress_bar = tqdm(val_dataloader)\n",
    "    for data in progress_bar:\n",
    "        loss, preds, confidences = forward(data, model, device)\n",
    "\n",
    "        #fix for the new environment\n",
    "        preds = preds.cpu().numpy()\n",
    "        world_from_agents = data[\"world_from_agent\"].numpy()\n",
    "        centroids = data[\"centroid\"].numpy()\n",
    "        coords_offset = []\n",
    "\n",
    "        # convert into world coordinates and compute offsets\n",
    "        for idx in range(len(preds)):\n",
    "            for mode in range(3):\n",
    "                preds[idx, mode, :, :] = transform_points(preds[idx, mode, :, :], world_from_agents[idx]) - centroids[idx][:2]\n",
    "\n",
    "        future_coords_offsets_pd.append(preds.copy())\n",
    "        confidences_list.append(confidences.cpu().numpy().copy())\n",
    "        timestamps.append(data[\"timestamp\"].numpy().copy())\n",
    "        agent_ids.append(data[\"track_id\"].numpy().copy()) \n",
    "    \n",
    "    pred_path = 'pred_short.csv'\n",
    "    write_pred_csv(pred_path,\n",
    "               timestamps=np.concatenate(timestamps),\n",
    "               track_ids=np.concatenate(agent_ids),\n",
    "               coords=np.concatenate(future_coords_offsets_pd),\n",
    "               confs = np.concatenate(confidences_list)\n",
    "              )\n",
    "\n",
    "    inference = OrderedDict()\n",
    "\n",
    "    for el in read_pred_csv(pred_path):\n",
    "        inference[el[\"track_id\"] + el[\"timestamp\"]] = el\n",
    "        \n",
    "    metrics = [neg_multi_log_likelihood, time_displace]\n",
    "    metrics_dict = defaultdict(list)\n",
    "\n",
    "    for key, ground_truth_value in ground_truth.items():\n",
    "        gt_coord = ground_truth_value[\"coord\"]\n",
    "        avail = ground_truth_value[\"avail\"]\n",
    "\n",
    "        # we subsampled the eval datset -> not every timestamp is available\n",
    "        if key in inference:\n",
    "            pred_coords = inference[key][\"coords\"]\n",
    "            conf = inference[key][\"conf\"]\n",
    "            for metric in metrics:\n",
    "                metrics_dict[metric.__name__].append(metric(gt_coord, pred_coords, conf, avail))\n",
    "\n",
    "    metric = {metric_name: np.mean(values, axis=0) for metric_name, values in metrics_dict.items()}\n",
    "#     print({metric_name: np.mean(values, axis=0) for metric_name, values in metrics_dict.items()})\n",
    "#     print(metric)\n",
    "    my_result = metric['neg_multi_log_likelihood']\n",
    "    print(weight_path, my_result)\n",
    "    results.append(my_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 4.819146,
     "end_time": "2020-11-14T18:52:32.989135",
     "exception": false,
     "start_time": "2020-11-14T18:52:28.169989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 2.690946,
     "end_time": "2020-11-14T18:52:35.819587",
     "exception": false,
     "start_time": "2020-11-14T18:52:33.128641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyc1Xno8d+ZRbs0Wka27BnZspG8S7Zl2RgkYgwpISQQYicsCYSmuaW5TVuSUlpuekOT29uWpjQl9DbNJYGUJFwgqU1CEqcJJLbBwfKK8YIsy5ZtLZa1jPZdM3PuHzMjZFu7ZuadV3q+n48+jN/ZnpHNo6PnPOccpbVGCCGE+ViMDkAIIcT0SAIXQgiTkgQuhBAmJQlcCCFMShK4EEKYlC2ab+Z0OnVeXl4031IIIUzvyJEjLVrr7KuvRzWB5+Xlcfjw4Wi+pRBCmJ5S6uJo16WEIoQQJiUJXAghTEoSuBBCmFRUa+CjGRoaoq6ujv7+fqNDMa2EhATcbjd2u93oUIQQUWR4Aq+rqyM1NZW8vDyUUkaHYzpaazweD3V1dSxZssTocIQQUWR4CaW/v5+srCxJ3tOklCIrK0t+gxFiDjI8gQOSvGdIvn9CzE0xkcCFECKa9p5p5mxTt9FhzNiECVwplauU2q2UqlBKnVJKPRK8/opS6ljw64JS6ljkww2/9vZ2vvWtb03ruXfccQft7e2TfvxXv/pVnnrqqWm9lxAiPAa9fj7/gyM89atKo0OZscmMwL3Ao1rrlcBm4AtKqVVa63u11uu01uuAHcDOSAYaKeMlcJ/PN+5zd+3aRXp6eiTCEkJEyIn6dvqGfJyo7zA6lBmbMIFrrRu01keDt7uACsAVul8FCrD3AC9FKshIevzxxzl37hzr1q3jscceY8+ePWzdupVPfepTFBYWAnD33XezYcMGVq9ezbPPPjv83Ly8PFpaWrhw4QIrV67kD//wD1m9ejW33XYbfX19477vsWPH2Lx5M0VFRXz84x+nra0NgGeeeYZVq1ZRVFTEfffdB8DevXtZt24d69atY/369XR1dUXouyHE7Fde3QpAfXsfLd0DBkczM1NqI1RK5QHrgQMjLt8ENGqtq2YazNd+dor3LnXO9GWusGphGn9z5+ox73/yySc5efIkx44FKkB79uzh4MGDnDx5crgt7/nnnyczM5O+vj42btzI9u3bycrKuuJ1qqqqeOmll/jOd77DPffcw44dO3jggQfGfN/PfOYz/Ou//itbtmzhiSee4Gtf+xpPP/00Tz75JOfPnyc+Pn64PPPUU0/xb//2b5SWltLd3U1CQsJMvy1CzFn7z3mIs1oY9Pk5Ud/B1uXzjA5p2iY9iamUSiFQKvmi1npklr2fcUbfSqmHlVKHlVKHm5ubpx9pFG3atOmKnupnnnmGtWvXsnnzZmpra6mquvZn1ZIlS1i3bh0AGzZs4MKFC2O+fkdHB+3t7WzZsgWAhx56iDfffBOAoqIiPv3pT/PDH/4Qmy3w87W0tJQ///M/55lnnqG9vX34uhBiaga9fg5fbOVj6xYCcLLO3GWUSWUCpZSdQPJ+UWu9c8R1G7AN2DDWc7XWzwLPApSUlIx7gvJ4I+VoSk5OHr69Z88e3njjDfbv309SUhI333zzqD3X8fHxw7etVuuEJZSx/OIXv+DNN9/ktdde42//9m85deoUjz/+OB/5yEfYtWsXmzdv5o033mDFihXTen0h5rLjde30D/n54Kr5HLnYxnGT18En04WigOeACq31N666+4PAaa11XSSCi4bU1NRxa8odHR1kZGSQlJTE6dOnKS8vn/F7OhwOMjIyeOuttwD4wQ9+wJYtW/D7/dTW1rJ161a+/vWv097eTnd3N+fOnaOwsJC/+qu/oqSkhNOnT884BiHG09DRx6e/W05dW6/RoYTV/nMelILrl2RS6HZwwuQj8MmUUEqBB4FbRrQN3hG87z5MOnkZkpWVRWlpKWvWrOGxxx675v7bb78dr9dLUVERX/nKV9i8eXNY3veFF17gscceo6ioiGPHjvHEE0/g8/l44IEHKCwsZP369XzpS18iPT2dp59+mjVr1rB27VoSExP58Ic/HJYYhBjLi+U1/O6sh18cbzA6lLAqP+9hZU4a6UlxFLocXO7sp6nLvKuYldbjVjXCqqSkRF99oENFRQUrV66MWgyzlXwfRbh4fX5K//G3NHYOcFOBkx987nqjQwqLAa+PtV/7NZ/atJgn7lzFgWoP9z5bzvO/X8ItK+YbHd64lFJHtNYlV1+XlZhCiCvsqWymsXOApdnJHDzfSv/Q+OshzOLd2g76h/xsXpoJwGqXA6XguInLKJLAhRBXePlQDdmp8fzlh1Yw4PVz5GKb0SGFRXl1qP4daAFOibdxXXYKJ008kRkTCTyaZZzZSL5/Ilwud/Tz29NNfGKDm7ICJzaLYt/ZFqPDCovyag+rFqThSHp/3/wil0NG4DORkJCAx+ORJDRNof3AZXGPCIf/PFKLX8O9JbmkxNtYvyidfVXmT+ADXh9HLraxeemVC/DWuBw0dQ3Q2GnOiUzDV4S43W7q6uowyyKfWBQ6kUeImfD7Na8cruWGpVnkOQNrIUrznXzzN1W09QySkRxncITTd6ymnQGv/5oEXuR2AHCiroP5q8w3CDI8gdvtdjlJRogY8PY5D7WtffzFbcuHr91U4OTpN6p4+5yHjxQtMDC6mSmvbkUp2LQk84rrqxamYVFwvL6DD66K7U6U0RheQhFCxIaXD9WQnmTnQ6tzhq8VudNJibeZvg5eXu1h9cI0HIlXnhubFGcjf14KJ+omvy10LJEELoSgtWeQX59q5OPrXSTYrcPX7VYLm5dm8TsTJ/D+IR9HatrYvCRr1PsLXemcqO805TycJHAhBDuP1jHo83PfxkXX3FeWn0VNay81HnMuqz9W287gKPXvkCK3g5buAS6bcCJTErgQc5zWmpcP1bJ+UTrLc1Kvub+swAlg2jJKebUHi4KNV9W/Q9a4AhOZZmwnlAQuxBx3tKaNs03d3Lcxd9T7r8tOISctgX1nzdkptv+ch9ULHdfUv0NWLUjDalGmXNAjCVyIOe6lg7Ukx1n5aNHCUe9XSlGa7+Ttcx58fnPVifuHfLxT2z68fH40iXFWCualyAhcCGEunf1D/OJ4A3etW0hy/NhdxTcVOGnvHeLUJXMluXdqAvXvG64bvf4dUuhycKK+w3QTmZLAhZjDXjt2ib4h36iTlyPdmB9IgGarg+8P1r9L8sYegUNgIrO1Z5BLHeaayJQELsQc9sqhWlbkpA6vSBzLvNQEVuSkmm5ZfXm1hzUuB2kJo9e/Qwrd6QCm6weXBC7EHHWyvoMT9R3cv2kRgYO3xlea7+TwhTb6Bs2xvWz/kI9jNe3cMEb74EgrclKxWZTp6uCSwIWYo145VEu8zcLd61yTenxZgZNBn59DF1ojHFl4HK1pY9A3dv/3SAl2K8vmp3LCZJ0oksCFmIP6Bn385Fg9dxQuuGJ71fFcvyQTu1WZZlVm+blQ/TtjUo8vcptvIlMSuBBz0K4TDXT1e7l3jN7v0STF2ShelGGaiczy6lYKXQ5SJ6h/h6xxOWjvHaKurS/CkYWPJHAh5qCXD9WwxJnM9WOsThxLWb6TU5c68XQPRCiy8Ogb9HGstp3NE7QPjhSayDVTHVwSuBBzzNmmbg5daOPejbmTmrwcqTS4rP7tc55IhBY2U6l/hyzPScVuVaaqg0sCF2KOeeVQDTaLYnvx1A8BKXI5SE2wxXw7YXm1B6tFsXGC/u+R4m1WluekcqLePK2EksCFmEMGvX52HK3ngyvnk50aP+Xn26wWbliaxb6zLTE92Vde7aHQ5SBlnNWloyl0pXOizjwTmZLAhZhDXn+vkdaeQe7bNPnJy6vdVOCkvr2PCzG6vexw/XsK5ZOQIreDzn4vNa2x+dmuJglciDnk5UM1uNITuakge9qvUZof29vLHrnYxpBPj7uB1VgKTba1rCRwIeaI2tZe9p1t4ZMlbqyWqU1ejrTEmYwrPZF9VbG5vex06t8hy+anEme1mGYiUxK4EHPEjw/XAvDJkumXTyC0vWxWzG4vu7/aQ5HbMe7uimOJs1lYuSCVEzICF0LECq/Pz48O17FlWTau9MQZv15ZQTZd/d6YG6n2Dnp5d5r175BCt4OT9R34Y/CH09UmTOBKqVyl1G6lVIVS6pRS6pER9/2pUqoyeP3rkQ1VCDFdb1Y1c7mzf8xTd6bqxuACmVgroxy52IbXr2eWwF0Ouga8XPD0hDGyyJjMCNwLPKq1XglsBr6glFqllNoKfAwo0lqvBp6KYJxCiBl46WAtzpQ4bl05Pyyv50yJZ9WCtJibyCyv9mCzKEoWT27/k9EUuoJby8bYbxejmTCBa60btNZHg7e7gArABfx34Emt9UDwvqZIBiqEmJ6mzn5+e7qJ7Rvc2K3hq5qWFTg5crGN3kFv2F5zpvafm379O6RgfgrxNosp6uBT+ttUSuUB64EDwDLgJqXUAaXUXqXUxvCHJ4SYqR8fqcPn1xOeujNVpflOhnyag+djY3vZngEvx+s6ZlQ+AbBbLaxckMbx2TACD1FKpQA7gC9qrTsBG5BBoKzyGPAjNcrGCkqph5VSh5VSh5ubY6teJsRs5/drfnS4luuXZLLEmRzW196Ul0mc1RIzy+pD9e+Jzr+cjCK3g1MmmMicVAJXStkJJO8XtdY7g5frgJ064CDgB5xXP1dr/azWukRrXZKdPf3FA0KIqSs/7+Gip5f7N4V39A2B09w3LI6d7WX3B+vfG2ZQ/w4pdDnoGfRR3RLbE5mT6UJRwHNAhdb6GyPu+glwS/Axy4A4IDb+JoUQALx8sJa0BBu3r8mJyOuXFTg5fbmL5i7jt5ctr/awNjedpLjp179DCoNby8b6xlaTGYGXAg8CtyiljgW/7gCeB5YqpU4CLwMPabPsACPEHNDWM8h/nbzMtmI3CXZrRN6jLD+0vayxY7dQ/Xsy519ORn52Cgl2CyfqOsPyepEy4Y8qrfU+YKx1tw+ENxwhRLi8+k49gz7/lE7dmao1LgeORDv7qlr42CTP1oyEQxda8c2w/3skm9XC6oWOWTECF0KYjNaaVw7VsjY3nZUL0iL2PlaL4sbrjN9etry6FbtVUbw4PWyvWehycLK+Mya3CwiRBC7ELPRObTuVjV1hW3k5nrICJw0d/YZO+JVXe1jrDk/9O6TQ5aBvyEd1c3fYXjPcJIELMQu9crCWpDgrd65dGPH3CtXBjWon7B4I7MkSjvbBkcxwRqYkcCFmme4BLz87fok7ixZO+USa6ViUmYQ7I9GwdsJw179DlmankBRnjekl9ZLAhZhlfvbuJXoHfdw7g1N3pkIpxU0FTsrPefD6/FF5z5HKqz2B+veimfd/j2S1KFYvTJMELoSInpcP1rB8firrc8M3oTeR0nwnXQNe3jWg3FBe3cr63AwS48LfKlnoSufUpQ5DfjBNhiRwIWaR9y518m5dB/duzGWUnS0i5sbrnCgV/Tp4V/8QJ+s7pnV82mQUutPoH/JzNkYnMiWBCzGLvHKohjibhW3F0e3JzkyOY/XCNH4X5Tr44QttEal/hwxvLRujE5mSwIWYJfqHfLz6Tj23r84hPSku6u9flp/N0Zo2egait71sebWHOKuF4jDsfzKapc5kkmN4IlMSuBCzxC9PNtDZ7+W+KE1eXq0s34nXrzlw3hO199xf7WHdovSIbRVgsSjWuBwx20ooCVyIWeLlg7Uszkpi85LIlBMmUpKXQbzNwr6q6CTwzuH6d2Q/b6HLQUVDJ0MxOJEpCVyIWaC6uZsD51u5d2MuFkv0Ji9HSrBb2ZiXyb6z0dn3//CFVvyaiE1ghhS6HQx4/VQ1xt5EpiRwIWaBVw7XYrUoPlHsNjSOsgInZxq7aersj/h77T/nIc5mCXv/99WK3KEzMmNvYytJ4EKY3KDXz44jddy6Yh7z0hIMjWV4WX0UulEC/d+Rq3+HLM5MIjXeFpMTmZLAhTC5355upKV70LDJy5FWLUgjI8ke8QTe0TfEqUuRr3/D+xOZsdhKKAlcCJN76WAtOWkJbFk2z+hQsFgUN+Y72VcV2e1lD50P1L/DvYHVWIrcDioauhj0xtZEpiRwIUysvr2PN6uauafEjdWgycurleU7aeoa4GxT5Cb9yqsD9e91UdouYI3LwaDPz5nGrqi832RJAhfCxH50qBaAT5YYXz4JiUYdvPy8h+II9n9frWj4jMzYKqNIAhfCpHx+zY8P11KW7yQ3M8nocIblZiaxOCspYvuiBOrfndyw1BmR1x/Noswk0hJsMbegRxK4ECb1ZlUzlzr6uX/TIqNDuUZZvpPyak9EFr8cPN+KjkL/90hKKQrdsXdGpiRwIUzqlYO1ZCXH8cGV840O5Rpl+U56Bn0cqw1/wiuv9hBvs7A2itvlQmBjq8rLXQx4fVF93/FIAhfChJq7BnijopHtG9zE2WLvf+NIbi9bXu2heFFG1OrfIUVuB0M+TeXl2JnIjL2/eSHEhHYcrcPr19wTQ5OXIzmS7BS5HGGfyGzvHeS9hs6otQ+OVOiKvTMyJYELYTJaa145VMumvEzy56UYHc6YygqcHKttp6t/KGyv+X79O/oJ3J2RSHqSnZMx1IkiCVwIkzlwvpXzLT3cuzE2R98hpflOfH5NeXVr2F6zvLo1WP92hO01J0spRWGMbS0rCVwIk3n5YA2pCTbuKFxgdCjj2rA4gwS7Jayn9Oyv9gS3rY1u/Tuk0OXgTGMX/UOxMZEpCVwIE+noHWLXycvcvc4VkUN8wyneZmXTkizeqgrP9rLtvYOcvtxp2H7nEJjI9Po1p2NkIlMSuBAm8uo7dQx6/TGxcdVklOVnca65h4aOvhm/1oFQ/duACcyQwtDWsnWx0Q8uCVyIaeroG2LvmWaO1rRR3dxNW88gPn/kNnDSWvPyoVoKXQ5WL4x+DXg6yvKzAfjd2Zmf0rP/nIcEu4W17uj2f4+00JFAZnJczNTBbRM9QCmVC3wfyAH8wLNa628qpb4K/CEQ+v3oy1rrXZEKVIhYUuPp5cHnD3DR03vNfWkJNtKT4khPsuNItJMRvJ2eaMeRFEd6oj3w5yR74HGJgcfZrOOPp47XdXD6chd/9/E1kfpYYbciJ5Ws5Dj2VTXziQ0zO2yivNpDyeJMQ/veQxOZsbInyoQJHPACj2qtjyqlUoEjSqnXg/f9i9b6qciFJ0TsqWjo5DPPH2TI5+fbDxQTb7PS3jdIe+8Q7b1DdPQN0d47SHvfEG29Q9S29tLeF7g+3g6rqfE2HKHEnhj3fpIP3t53toVEu5W71i6M3oedIYtFUZrvZN9ZD1prlJrejoltPYOcvtzFX9xm/MRtkdvBt/a00DfoM3weYsIErrVuABqCt7uUUhWAK9KBCRGLDl1o5Q/+4xDJcTb+3x/dQMH81Ek/1+/XdPV730/2oUQfTPztfYN0jLh+qb1v+HaoMnP/pkWkJtgj9OkioyzfyWvvXqKysYsVOWnTeo0D5wOtiEb0f1+t0OXA59e819DJhsWRPc5tIpMZgQ9TSuUB64EDQCnwJ0qpzwCHCYzS20Z5zsPAwwCLFsXepjtCTNZvKhr54xeP4kpP5Puf24Q7Y2o7AFosCkeSHUeSncVTyEN+v6Z70EtH7xA5DmOPTJuO0oLg9rJVLdNO4OXVHhLt1uHzKY1UGNxa9mR9h+EJfNLFJKVUCrAD+KLWuhP4d+A6YB2BEfo/j/Y8rfWzWusSrXVJdnZ2GEIWIvp2HKnj4R8cYdn8VH78+RumnLxnwmJRpCXYyc1Mwj5BnTwWudITWepMntGy+vJg/3cs7PuSk5aAMyU+JiYyJ/XdUErZCSTvF7XWOwG01o1aa5/W2g98B9gUuTCFMM5336rm0R+/y/VLMnnp4c1kpcQbHZLplBU4OVDdOq0jyVqD9e9YKJ9AYCKzKEa2lp0wgavArMNzQIXW+hsjro+cTfg4cDL84QlhHK01X/+v0/zvX1Tw4TU5fO+zG0mJn1LVUQSV5jvpG/JxtOaaKuuEDlQHWhBjJYFD4Ii1s03d9A56DY1jMiPwUuBB4Bal1LHg1x3A15VSJ5RSx4GtwJciGagQ0eTza7786gm+tecc929axP/5VLFhy7dng81Ls7AoprWs/v36d+z0vhe5HPg1vHep09A4JtOFsg8YrfdHer7FrDTg9fHFl4/xy5OX+cLW6/iL25ZPu/1NBDgS7azNTWff2RYevW35lJ5bXt1KSV5GTNX/QxOZx+s6KMmL3slAV4ud74gQMaB7wMtnv3eIX568zFc+uorHPrRCkneYlOU7ebe2nY6+yW8v6+keoLKxy5D9v8czPy2Beanxhm8tKwlciCBP9wD3P1vOgfOtfOOetXyubInRIc0qZflO/DpQEpmsWOr/vlqR28FxSeBCGK+urZdPfns/Zxq7ePbBDWwrntmyb3Gt9YsySIqzTumYtfJqD0lx1uHTcGJJoSudc83ddA8YN5EpCVzMeWcau/jEv++npXuAH/6367k1Bg8Jng3ibBauX5I5pYnM/ec8lORlxlT9O6TQnYY2eCIz9r4rQkTR0Zo2Pvnt/fi05pU/uoGNBk5IzQWl+U6qW3qob594e9mW7gGqmrq5IQbLJxBoJQQ4buDWspLAxZy190wzn/7OAdKT7Oz4/I2sXDC9Zd5i8m4qCG4vO4kyyoHqUP07Nn+ozktNYIEjwdCdCSWBiznptXcv8d9eOESeM5kff/4GFmVFb2n8XLZsfgrZqfG8NYkySnm1h+Q46/BINxatMXhrWUngYs75/v4LPPLyO6xflMErf7SZeanm2yDKrJRSlOU7eftsC/4JDr/YX+1h45LYrH+HFLkcVDf30NU/+dbIcIrd74wQYaa15l9eP8MTPz3FrSvm8/0/2ESaybZmnQ1K8514gvubjKW5a4CzTd0x2T440vs7ExozkSkJXMwJfr/mb147xTd/U8UnNrj59gPFJNhlabwRyvKD28ueHfuw4wPnY2//k9GE2huNWtAjCVzMeoNeP3/28jt8f/9FHv7AUv7pE0UTHl8mIifHkUD+vBT2jXNO5v5zHlLibaxZGNsTy1kp8bjSEw1b0CP/isWs1jvo5XMvHOLnxxt4/MMr+PIdK2VpfAwoy3dy8LyH/iHfqPeXV3vYmJdhih+0hS6HYafUy96YIuxaewY509jFmcYuzjZ1Y7daWJyVxKLMwJc7IykqG/O39Qzy2f84xPG6dv5xeyH3bpQToWJFWb6T/3j7Akdr2rjxOucV9zV19XOuuYd7SnINim5qCt0O/uvUZTr6hnAkRndORRK4mLaOviGqGrs409g9nLDPNHbT0j0w/JjUBBtDPj/9Q+9v5G9RsMCRyKLMpEBiDyb3xZnJLMpMwpE08/8JGjr6ePC5g9S09vKtT2/g9jU5M35NET7XL83EalHsq2q5JoGXV8fu/iejCdXBT9V3cGO+c4JHh5ckcDGhngEvVU3BJH25izNN3Zy53MXlzv7hxyTHWcmfn8otK7JZNj91+Gt+WuD0muauAWpae7no6eViay+1rb1c9PTwRkUjLd2DV7yfI9HO4qwkcjOTWBwctS/KSmJxVjI5aQlYLeOXQM41d/OZ5w7S0TfEC5/dFHM72QlITbCzPjd91GX15dUeUuNtrI7x+ndIKIEflwQujNQ/5ONsUzdVTV1UXu6mqrGLysYu6treX/Ycb7OQPy+FG6/LomB+KstzUiiYl4orPRHLOIl1XloC89ISRt07uWfAO5zca1t7udjaw0VPL6fqO/jVyct4R/QLx1ktuDMSh0ftgVF88vDtqqYufv97h1DAyw9vjulFIHNdab6TZ35bRXvvIOlJccPXy4P932aofwNkJMeRm5loyIIeSeBz0KDXz/mWnhFlj0Dp46Knh1CutFsV12WnsH5RBvdtzA0k6/mp5GYmTTgCnqrkeBsrF6SNupTd6/PT0NE/YvTeExy993LkQhtdV+0EZ7UoctIS+MHnNrE0OyWscYrwuqnAyTd/U8X+cx4+XBg4obGxs5/q5h7u22iO+ndIYCJTEriIsB/sv8DXfvbe8KjWalHkZSWxIieVu9YuZFlwVL04KzkmVsDZrBZyMwPllNL8K+/TWtPeO8TF1l5qWnup8fTQ1e/ls6VLyHHI6spYtzY3neQ4K/vOtgwn8NBe4TcsjW4pYqYKXensOnH5mt8mIk0S+BzzyuFa8pzJ/Okt+Sybn8rS7GTTnvWolCIjOY6M5DjW5aYbHY6YIrvVwualWewbUQcvr24lNd7GKpPUv0OKRqzILCuI3g8f44dYImqaOvs5Wd/JtmIXH1vnYuWCNNMmbzE7lBU4h+c+IHAC/aYlmWEv00XamoWhiczo9oNLAp9D9pwJLF2+edk8gyMRIuD9ZfUtgfp3S48pu4YcSYHOqWjXwaWEMofsrWxmflo8KxekGh2KEADkz0thflo8+862kBQX+G3QLP3fVyt0OThWKyNwEQFDPj9vVjWzdfk8WUouYoZSitLg9rJvn/WQmmAz7cEahS4HdW19tPYMTvzgMJEEPkccvdhGV7+Xm5dL+UTElpsKnLT1DvHTd+u53oT175DQ1rLR7AeXBD5H7K5sxmZRlOab89dTMXuVBpfS9w/5TVs+gffPyIzmxlaSwOeIPZVNbMzLJFUOMBAxZl5aAsvnB+ZlzJzA0xLsLHEmywhchFdDRx+nL3exdUW20aEIMarbVs9noSPBtPXvkGivyJQEPgfsqQy2D0r9W8SoR24t4I1Ht5i2/h1S5HZwqaP/ih05I2nCBK6UylVK7VZKVSilTimlHrnq/r9QSmmllLnWvs4heyqbcKUnUjBP9gYRsclmtZAUZ/6u5uE6eJTKKJMZgXuBR7XWK4HNwBeUUqsgkNyB3wNqIheimIlBr599VS3cvDxb2geFiLDVC9NQiqiVUSZM4FrrBq310eDtLqACcAXv/hfgLwE9xtOFwQ5faKVn0MdWKZ8IEXGpCXaWOpM5HisJfCSlVB6wHjiglLoLqNdavzvBcx5WSh1WSh1ubh77FGoRGbsrm4izWrhR2geFiIpClyNqp9RPOoErpQGQvBoAABFdSURBVFKAHcAXCZRV/hp4YqLnaa2f1VqXaK1LsrOlCyLa9lQ2c/3SzFlRXxTCDArd6Vzu7KdpxIlVkTKpBK6UshNI3i9qrXcC1wFLgHeVUhcAN3BUKSUHD8aQ2tZeqpq6pftEiCgqiuKKzMl0oSjgOaBCa/0NAK31Ca31PK11ntY6D6gDirXWlyMarZiS4d0Hl8tvPkJEy6oFwYnMWEjgQCnwIHCLUupY8OuOCMclwmBvZROLMpNY6kw2OhQh5ozkeBv52SlR6USZsDCqtd4HjNt/FhyFixjSP+Tjd2c93FPilvZBIaKs0O3graqWiR84Q7ISc5Y6eL6VviEfN6+Q+rcQ0VbkctDcNUBjhCcyJYFf5fTlTh7+/mF+eqze6FBmZHdlE/E2CzeYeHMgIcwqtLVspPvBpbcsqLN/iKdfr+KF/Rfw+TVVTd3ctXahacsPeyubueG6LBLscualENG2aoEDiwpsLft7q+ZH7H3mfALXWvOTY/X8/a7TtHQP8KlNi8jLSubvdlVwtKadDYszjA5xyi609FDd0sNDN+YZHYoQc1JinJVl81Mj3okypxP46cudPPGTUxy80Mra3HSee6iEInc63QNe/vn1SnYerTNlAt9T2QRI+6AQRlrjcrCnsgmtdcR+k5+TNfDO/iH+18/e4yPP7KOqqYsntxXy6n+/kSJ3OgAp8TZuX53Dz969RP+Qz+Bop27PmWaWOpNZnCXtg0IYpcjtoKV7kIaOyE1kzqkErrXm1XfquPWf9/K9t89z38Zcfvvozdy3aRGWq/Yh3r7BTWe/l9+ebjIo2unpG/Sx/5xHVl8KYbDCKGwtO2dKKFeUS9yO4XLJWG68zsn8tHh2HKnjjsIFUYx0ZsqrPQx4/VI+EcJgKxekYbUoTtR18KHVkdllZNYn8JHdJWkJNp7cVsg9JbnXjLivZrUo7l7v4rtvnaelewBnSnx0Ap6h3ZVNJNqtbFqSaXQoQsxpCfbARObxCI7AZ20J5epyyb3jlEvGsr3Yjc+vee3YpQhHGx5aa/ZUNlOaL+2DQsSCouDWslpH5siEWZnAT1/u5N7/W86XXnmXhY4EfvqFUv7+44VkJMdN6XWWzU+l0OVgx9G6CEUaXtUtPdS09kr9W4gYscbtoLVnkPr2voi8/qwqoUy3XDKe7cUuvvqz9zh9uZMVObF9Yvbu09I+KEQsKQpNZNZ14M5ICvvrz4oReDjKJWO5c+1CbBbFzqOxv7R+75lmCualROQfihBi6lYsSMVuVRHrRDH9CHyq3SVTlZUSz9YV83j1nXr+8kPLsVlj82dez4CXA9Wt/H5pntGhCCGC4m2RXZFp2gR+dbnkH7YVcu8MyyVj2V7s4vX3Gtl3tiVm68tvn/Mw6PNz8zIpnwgRS4rcDnaduByRFZmxOZwcx1jlkvvDUC4Zy9YV80hPssd0GWV3ZRPJcVZK8qR9UIhYUuhKp6NviLq28E9kmmoEHulyyVjibVbuLFrIjw7X0tU/RGqCPeLvORVaa/ZWNlNW4CTOZrqfyULMaqEVmRUNneRmhnd+yhT/t4/cu+RMUxf/sK2QV/+4NCrJO2RbsYsBr59dJxqi9p6TVdXUTX17H1tjtLwjxFy2ckEqh//nB7ktAqsxTTEC/8pPTvLau5e4f9MiHrtt+ZT7ucNhXW46S7OT2XG0nns3Lor6+48n1D64RdoHhYg5NqslYiu5TZHAv/TBZfxB6RLW5kZvxH01pRTbi938068qqW3tDfuvQjOxp7KZFTmpLHAkGh2KECKKTFFCyXMmG5q8Q+5e70IpYmoys6t/iEMXWtkqZ18KMeeYIoHHCld6IjcszWLnO3UR29tgqn53tgWvX0v7oBBzkCTwKdpe7Oaip5cjF9uMDgWA3aebSU2wUWzCk4OEEDMjCXyKbl+TQ1KclR0xUEbRWrPnTBMfKMjGHqMrRIUQkSP/109RcryN29fk8PPjxh+3VtHQRWPngGxeJcQcJQl8GrYXu+nq9/JGRaOhceyulPZBIeYySeDTsHlpFgscCew4Yuw+4Xsrm1njSmNeaoKhcQghjCEJfBqsFsXH17t4s6qFpq7InTg9no7eIY7UtMnqSyHmsAkTuFIqVym1WylVoZQ6pZR6JHj9b5VSx5VSx5RSv1ZKLYx8uLFjm8HHrb11thmfX0v9W4g5bDIjcC/wqNZ6JbAZ+IJSahXwT1rrIq31OuDnwBMRjDPm5M9LYW1uumHdKLtPN5OeZGddrrQPCjFXTZjAtdYNWuujwdtdQAXg0lp3jnhYMhAbK1uiaHuxi4qGTt671Dnxg8PI79fsPdPMBwqysUZoC10hROybUg1cKZUHrAcOBP/8d0qpWuDTjDECV0o9rJQ6rJQ63NzcPLNoY8ydRQuxWxU7o3zo8alLnbR0S/ugEHPdpBO4UioF2AF8MTT61lr/tdY6F3gR+JPRnqe1flZrXaK1LsnOnl0JJyM5jltWzOMnxy7h9fmj9r67K5tQCj4gy+eFmNMmlcCVUnYCyftFrfXOUR7y/4Dt4QzMLLYXu2npHuCtqpaoveeeyiaK3OkR26JSCGEOk+lCUcBzQIXW+hsjrheMeNhdwOnwhxf7bl4+j4wkOzuiVEZp7Rnkndp2tkr5RIg5bzL7gZcCDwInlFLHgte+DHxOKbUc8AMXgc9HJsTYFmezcNfahbx0qJaOviEciZE9bu2tqma0JmYPVxZCRM+ECVxrvQ8YrdVhV/jDMaftG9y8sP8iu040cP+myJ7Ws/t0E1nJcRQFz9kTQsxdshIzDApdDvLnpUR8ab3Pr3mzqoUty7KxSPugEHOeJPAwCB23dvhiGxc9PRF7n+N17bT2DMrmVUIIQBJ42Ny9fmHEj1vbXdmMRcEHCiSBCyEkgYfNAkciZflOdr5Th98fmUWpeyubWL8og4zkuIi8vhDCXCSBh9G2Yhe1rX0cjsBxa81dA7xb1yHtg0KIYZLAw+hDq3NIjrNGZDLzzTOBbQikfVAIESIJPIyS4mx8uHABvzjREPbj1nZXNpGdGs+qBWlhfV0hhHlJAg+zbcUuuge8/OrU5bC9ptfn562qFm6W9kEhxAiSwMNs85IsXOmJYe1GOVbbTkffkJRPhBBXkAQeZpbgcWtvVTXT1Bme49Z2VzZhtSjKCpxheT0hxOwgCTwCthW78Gv4ybHwjML3VDazYXFGxPdZEUKYiyTwCFiancL6RensOFKP1jPrCW/s7OfUpU45vEEIcQ1J4BGyvdhNZWMXp2Z43NreykD7oJw+L4S4miTwCPlo0QLirJYZT2burmwiJy2BFTmpYYpMCDFbSAKPkPSkOG5dOY+fHqtnaJrHrQ35/OyramHrimwC52oIIcT7JIFH0PZiN56eweFVlFN15GIbXQNetiyT8okQ4lqSwCNoy/JsspLjpn3c2u7KJuxWRWl+VpgjE0LMBpLAI8hutXDXuoW88V4THb1DU37+3spmNuZlkpog7YNCiGtJAo+w7cVuBn1+fn7i0pSed6m9j9OXu6R9UAgxJkngEbZ6YRrL56dOeYfCPdI+KISYgCTwCFNKsa3YxdGads63TP64td2VTbjSE8mflxLB6IQQZiYJPAruXu/ComDnJCczB7w+3j4r7YNCiPFJAo+C+WkJlBVks/No/aSOWzt8oY2eQR83S/ugEGIcksCjZHuxi/r2Pg6cb53wsbtPNxFntXCjtA8KIcYhCTxKbluVQ0q8bVJllD1nmrl+aSZJcbYoRCaEMCtJ4FGSGGfljsIcdp1ooG9w7OPWalt7OdvULYc3CCEmJAk8irYXu+kZ9I173NqeyiYAOX1eCDEhSeBRtDEvE3dG4rhL63dXNrM4K4klzuQoRiaEMKMJE7hSKlcptVspVaGUOqWUeiR4/Z+UUqeVUseVUq8qpdIjH665WSyKbcVufne2hcsd1x631j/k4+1zLWxdPk/aB4UQE5rMCNwLPKq1XglsBr6glFoFvA6s0VoXAWeA/xG5MGePbevHPm7twPlW+of8bJHyiRBiEiZM4FrrBq310eDtLqACcGmtf6219gYfVg64Ixfm7JHnTGbD4gx2HKm75ri13aebiLdZuGGptA8KISY2pRq4UioPWA8cuOquPwB+OcZzHlZKHVZKHW5unt6+2LPN9mI3VU3dnKy/8ri1vWeaufG6LBLsVoMiE0KYyaQTuFIqBdgBfFFr3Tni+l8TKLO8ONrztNbPaq1LtNYl2dlSGgD4SNEC4myWKyYzz7f0cL6lR9oHhRCTNqkErpSyE0jeL2qtd464/hDwUeDTeqbHr88hjkQ7v7dqPq+9e4lBb+C4tffbByWBCyEmZzJdKAp4DqjQWn9jxPXbgb8C7tJa90YuxNlpe7GL1p5B9gaPW9td2czS7GQWZSUZHJkQwiwmMwIvBR4EblFKHQt+3QH8HyAVeD147duRDHS2+UBBNs6UOHYcqaNv0Ed5tUc2rxJCTMmEm21orfcBozUl7wp/OHOHzWrhY+tcfH//BX55soFBr5+tK2SOQAgxebIS00Dbi90M+TR/94sKEu1WNi3JNDokIYSJSAI30KqFaazIScXTM0hpvpN4m7QPCiEmTxK4wbYXB9Y/yeHFQoipkg2nDXbPxlwudfRx59qFRocihDAZSeAGcyTa+Zs7VxsdhhDChKSEIoQQJiUJXAghTEoSuBBCmJQkcCGEMClJ4EIIYVKSwIUQwqQkgQshhElJAhdCCJNS0TyHQSnVDFyc5tOdQEsYw4k1s/nzyWczr9n8+cz02RZrra/ZbyOqCXwmlFKHtdYlRscRKbP588lnM6/Z/Plmw2eTEooQQpiUJHAhhDApMyXwZ40OIMJm8+eTz2Zes/nzmf6zmaYGLoQQ4kpmGoELIYQYQRK4EEKYlCkSuFLqdqVUpVLqrFLqcaPjCRelVK5SardSqkIpdUop9YjRMYWbUsqqlHpHKfVzo2MJN6VUulLqP5VSp4N/hzcYHVO4KKW+FPw3eVIp9ZJSKsHomGZCKfW8UqpJKXVyxLVMpdTrSqmq4H8zjIxxOmI+gSulrMC/AR8GVgH3K6VWGRtV2HiBR7XWK4HNwBdm0WcLeQSoMDqICPkm8F9a6xXAWmbJ51RKuYA/A0q01msAK3CfsVHN2H8At1917XHgN1rrAuA3wT+bSswncGATcFZrXa21HgReBj5mcExhobVu0FofDd7uIpAAXMZGFT5KKTfwEeC7RscSbkqpNOADwHMAWutBrXW7sVGFlQ1IVErZgCTgksHxzIjW+k2g9arLHwNeCN5+Abg7qkGFgRkSuAuoHfHnOmZRkgtRSuUB64EDxkYSVk8Dfwn4jQ4kApYCzcD3giWi7yqlko0OKhy01vXAU0AN0AB0aK1/bWxUETFfa90AgcEUMM/geKbMDAlcjXJtVvU+KqVSgB3AF7XWnUbHEw5KqY8CTVrrI0bHEiE2oBj4d631eqAHE/4KPppgLfhjwBJgIZCslHrA2KjEaMyQwOuA3BF/dmPyX+dGUkrZCSTvF7XWO42OJ4xKgbuUUhcIlL1uUUr90NiQwqoOqNNah35j+k8CCX02+CBwXmvdrLUeAnYCNxocUyQ0KqUWAAT/22RwPFNmhgR+CChQSi1RSsURmEx5zeCYwkIppQjUUCu01t8wOp5w0lr/D621W2udR+Dv7Lda61kzitNaXwZqlVLLg5duBd4zMKRwqgE2K6WSgv9Gb2WWTNBe5TXgoeDth4CfGhjLtNiMDmAiWmuvUupPgF8RmA1/Xmt9yuCwwqUUeBA4oZQ6Frz2Za31LgNjEpP3p8CLwYFFNfBZg+MJC631AaXUfwJHCXRKvYPJl50rpV4CbgacSqk64G+AJ4EfKaU+R+CH1ieNi3B6ZCm9EEKYlBlKKEIIIUYhCVwIIUxKErgQQpiUJHAhhDApSeBCCGFSksCFEMKkJIELIYRJ/X8qj3ZSQIhM8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_train = results\n",
    "plt.plot(np.arange(len(losses_train)), losses_train, label=\"train loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 492.782163,
   "end_time": "2020-11-14T18:52:36.757988",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-14T18:44:23.975825",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "107c83506bf541919da5dc02d82a9404": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a97cada632b477e93dbb6636c6b4e43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "771686ab8b6344c894c0818dbd7a8d5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7e67adac3ac549268381fbc0f3ebb1c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ad802d671c3f47e88dbb8f14c012bc0a",
        "IPY_MODEL_93cd31e525fe4df3b3e29b4ca6eb3c04"
       ],
       "layout": "IPY_MODEL_96732210c086463490e0e82da896d5ac"
      }
     },
     "93cd31e525fe4df3b3e29b4ca6eb3c04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fff5fb0914694e7fad9e1589034534c4",
       "placeholder": "​",
       "style": "IPY_MODEL_771686ab8b6344c894c0818dbd7a8d5f",
       "value": " 83.3M/83.3M [00:11&lt;00:00, 7.57MB/s]"
      }
     },
     "96732210c086463490e0e82da896d5ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad802d671c3f47e88dbb8f14c012bc0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_107c83506bf541919da5dc02d82a9404",
       "max": 87306240,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5a97cada632b477e93dbb6636c6b4e43",
       "value": 87306240
      }
     },
     "fff5fb0914694e7fad9e1589034534c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
